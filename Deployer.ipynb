{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registering model model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/8y/0g_q78s11fs7byv7zy57g1v40000gn/T/ipykernel_4358/788481890.py:82: FutureWarning: azureml.core.model:\n",
      "To leverage new model deployment capabilities, AzureML recommends using CLI/SDK v2 to deploy models as online endpoint, \n",
      "please refer to respective documentations \n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-deploy-managed-online-endpoints /\n",
      "https://docs.microsoft.com/azure/machine-learning/how-to-attach-kubernetes-anywhere \n",
      "For more information on migration, see https://aka.ms/acimoemigration \n",
      "To disable CLI/SDK v1 deprecation warning set AZUREML_LOG_DEPRECATION_WARNING_ENABLED to 'False'\n",
      "  service = Model.deploy(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2025-03-31 17:43:03-06:00 Creating Container Registry if not exists..\n",
      "2025-03-31 17:53:04-06:00 Registering the environment.\n",
      "2025-03-31 17:53:06-06:00 Building image..\n",
      "2025-03-31 18:02:19-06:00 Generating deployment configuration.\n",
      "2025-03-31 18:02:20-06:00 Submitting deployment to compute..\n",
      "2025-03-31 18:02:29-06:00 Checking the status of deployment service-bankruptcy..\n",
      "2025-03-31 18:03:36-06:00 Checking the status of inference endpoint service-bankruptcy.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "‚úÖ Despliegue exitoso.\n",
      "üîó URI del endpoint: http://0ad22dee-50c4-4abd-afde-2831bd2566a4.centralindia.azurecontainer.io/score\n"
     ]
    }
   ],
   "source": [
    "# STEP 1 - Set up Azure ML workspace\n",
    "import json\n",
    "from azureml.core import Workspace, Environment\n",
    "from azureml.core.model import Model\n",
    "from azureml.core.environment import CondaDependencies\n",
    "from azureml.core.model import InferenceConfig\n",
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "my_id = \"_____\"\n",
    "\n",
    "ws = Workspace.get(\n",
    "    name=\"workspace\",\n",
    "    subscription_id=my_id,\n",
    "    resource_group=\"resource_group2\"\n",
    ")\n",
    "\n",
    "# registrar el modelo\n",
    "mname = \"model\"\n",
    "registered_model = Model.register(\n",
    "    model_path=\"model_bankruptcy.pkl\",\n",
    "    model_name=mname,\n",
    "    workspace=ws\n",
    ")\n",
    "\n",
    "# cargar umbral \n",
    "with open(\"umbral_bankruptcy.json\", \"r\") as umb:\n",
    "    umbral = json.load(umb)[\"umbral\"]\n",
    "\n",
    "# Crear archivo score.py\n",
    "scorepy = f\"\"\"\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from azureml.core.model import Model\n",
    "\n",
    "def init():\n",
    "    global model\n",
    "    model_path = Model.get_model_path('{mname}')\n",
    "    model = joblib.load(model_path)  # (xgb_model, logistic_model)\n",
    "    global xgb_model, logistic_model\n",
    "    xgb_model, logistic_model = model\n",
    "\n",
    "def run(raw_data):\n",
    "    try:\n",
    "        data = json.loads(raw_data)['data'][0]\n",
    "        df = pd.DataFrame(data)\n",
    "\n",
    "        # Obtener probabilidades de XGBoost\n",
    "        xgb_probs = xgb_model.predict_proba(df)[:, 1].reshape(-1, 1)\n",
    "\n",
    "        # Aplicar regresi√≥n log√≠stica sobre las probabilidades\n",
    "        final_probs = logistic_model.predict_proba(xgb_probs)[:, 1]\n",
    "\n",
    "        # Aplicar umbral din√°mico\n",
    "        umbral = {umbral}\n",
    "        final_preds = [1 if p > umbral else 0 for p in final_probs]\n",
    "\n",
    "        return json.dumps(final_preds)\n",
    "\n",
    "    except Exception as e:\n",
    "        return json.dumps(str(e))\n",
    "\"\"\"\n",
    "\n",
    "with open(\"score.py\", \"w\") as f:\n",
    "    f.write(scorepy)\n",
    "\n",
    "# STEP 2 - Configuraci√≥n del entorno\n",
    "virtual_env = Environment(\"env-bankruptcy-model\")\n",
    "virtual_env.python.conda_dependencies = CondaDependencies.create(\n",
    "    conda_packages=[\"pandas\", \"scikit-learn\", \"xgboost\", \"numpy\", \"joblib\"]\n",
    ")\n",
    "\n",
    "inference_config = InferenceConfig(\n",
    "    environment=virtual_env,\n",
    "    entry_script=\"score.py\"\n",
    ")\n",
    "\n",
    "aci_config = AciWebservice.deploy_configuration(cpu_cores=0.5, memory_gb=1)\n",
    "\n",
    "# STEP 3 - Desplegar el servicio\n",
    "service = Model.deploy(\n",
    "    workspace=ws,\n",
    "    name=\"service-bankruptcy\",\n",
    "    models=[registered_model],\n",
    "    inference_config=inference_config,\n",
    "    deployment_config=aci_config,\n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "service.wait_for_deployment(show_output=True)\n",
    "\n",
    "# Guardar URI del servicio\n",
    "scoring_uri = service.scoring_uri\n",
    "with open(\"uri.json\", \"w\") as f:\n",
    "    json.dump({\"URI\": [scoring_uri]}, f)\n",
    "\n",
    "print(\"Despliegue exitoso.\")\n",
    "print(\"URI del endpoint:\", scoring_uri)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
